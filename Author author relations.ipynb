{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bigjson\n",
    "import ijson\n",
    "import json\n",
    "import io\n",
    "import re\n",
    "import numpy as np\n",
    "from array import *\n",
    "from array import array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract files from the dataset\n",
    "#with open('E:/dblp_jason.json', encoding=\"utf-8\") as f:\n",
    "    #data = json.load(f)\n",
    "data=json.load(io.open('D:/Short Datasets/DBLP_sample.json', 'r', encoding='utf-8-sig'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1091, 'authors': [{'name': 'Makoto Satoh', 'org': 'Shinshu University', 'id': 2312688602}, {'name': 'Ryo Muramatsu', 'org': 'Shinshu University', 'id': 2482909946}, {'name': 'Mizue Kayama', 'org': 'Shinshu University', 'id': 2128134587}, {'name': 'Kazunori Itoh', 'org': 'Shinshu University', 'id': 2101782692}, {'name': 'Masami Hashimoto', 'org': 'Shinshu University', 'id': 2114054191}, {'name': 'Makoto Otani', 'org': 'Shinshu University', 'id': 1989208940}, {'name': 'Michio Shimizu', 'org': 'Nagano Prefectural College', 'id': 2134989941}, {'name': 'Masahiko Sugimoto', 'org': 'Takushoku University, Hokkaido Junior College', 'id': 2307479915}], 'title': 'Preliminary Design of a Network Protocol Learning Tool Based on the Comprehension of High School Students: Design by an Empirical Study Using a Simple Mind Map', 'year': 2013, 'n_citation': 1, 'page_start': '89', 'page_end': '93', 'doc_type': 'Conference', 'publisher': 'Springer, Berlin, Heidelberg', 'volume': '', 'issue': '', 'doi': '10.1007/978-3-642-39476-8_19', 'references': [2005687710, 2018037215], 'indexed_abstract': {'IndexLength': 58, 'InvertedIndex': {'tool.': [42], 'study': [4], 'aim': [37], 'purpose': [1], 'scientific': [17], 'for': [11], 'aspects': [18], 'students': [14, 46], 'focus': [27], 'hands-on': [47], 'learning': [9, 41], 'experience': [48], 'our': [40], 'we': [26], 'network': [33, 56], 'The': [0], 'More': [24], 'high': [12], 'protocols.': [57], 'school': [13], 'and': [21], 'of': [2, 19, 32, 55], 'communication': [22], 'protocols': [34], 'gives': [45], 'on': [28], 'a': [8], 'studying': [15], 'specifically,': [25], 'this': [3], 'understand': [51], 'is': [5], 'develop': [7, 39], 'Our': [43], 'tool': [10, 44], 'the': [16, 29, 36, 52], 'help': [50], 'as': [35], 'principles': [31, 54], 'information': [20], 'networks.': [23], 'to': [6, 38, 49], 'basic': [30, 53]}}, 'venue': {'raw': 'International Conference on Human-Computer Interaction', 'id': 1127419992, 'type': 'C'}}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#author-author relations code\n",
    "i=0\n",
    "authors_array=[]\n",
    "while i<len(data):\n",
    "    authors_data=data[i]\n",
    "    if 'authors' in authors_data:\n",
    "        authors=authors_data['authors']\n",
    "        for x in authors:\n",
    "            authors_array.append(x['id'])\n",
    "        \n",
    "        if len(authors_array)>1 and x['id']:\n",
    "            oneauthor=authors_array\n",
    "            k=0\n",
    "            for rel in oneauthor:\n",
    "                k=k+1\n",
    "                j=k\n",
    "                while j<len(oneauthor):\n",
    "                    with open(\"D:/Short Datasets/DBLP_V12_Relations/IR/author_author.txt\", \"a+\") as text_file:\n",
    "                        text_file.write(\"%s %s %s\"  % (rel, oneauthor[j], 1))\n",
    "                        text_file.write(\"\\n\")\n",
    "\n",
    "                    j=j+1\n",
    "        authors_array=[]\n",
    "    i=i+1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paper-paper reference relation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "while i<len(data):\n",
    "    paper=str(data[i])\n",
    "    paper1=eval(paper)\n",
    "    paper_id=paper1['id']\n",
    "    if 'references' in paper1:\n",
    "        for x in paper1['references']:\n",
    "            #print(paper_id, x, 1)\n",
    "            dictionary={\n",
    "            \"id\":paper_id,\n",
    "            \"reference\":x,\n",
    "                \"value\":1\n",
    "    }\n",
    "            with open(\"D:/Short Datasets/DBLP_V12_Relations/IR/papers_references.txt\", \"a+\") as text_file:\n",
    "                text_file.write(\"%s %s %s\"  % (paper_id, x, 1))\n",
    "                text_file.write(\"\\n\")\n",
    "                #text_file.close()\n",
    "            \n",
    "    i=i+1 \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#author-paper relations code\n",
    "i=0\n",
    "while i<len(data):\n",
    "    authors=data[i]\n",
    "    paper=str(data[i])\n",
    "    paper1=eval(paper)\n",
    "    paper_id=paper1['id']\n",
    "    if 'references' in paper1 and 'authors' in paper1:\n",
    "    #x=re.search(r\"references\", paper)\n",
    "    #if (x!=None):\n",
    "            for author in authors[\"authors\"]:\n",
    "                for x in paper1['references']:\n",
    "                    with open(\"D:/Short Datasets/DBLP_V12_Relations/IR/authors_papers.txt\", \"a+\") as text_file:\n",
    "                        text_file.write(\"%s %s %s\"  % (author[\"id\"], x, 1))\n",
    "                        text_file.write(\"\\n\")\n",
    "                        #text_file.close()\n",
    "    i=i+1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "import pandas as pd\n",
    "import io\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "file = 'D:/Short Datasets/DBLP_V12_Relations/DBLP_CS.json'\n",
    "df = pd.read_json(file)\n",
    "print('loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = '/home/ali/Datasets/Encoded_datasets/tagsold.json'\n",
    "# df = pd.read_json(file)\n",
    "# data=json.load(io.open('/home/ali/Datasets/New_Datasets/DBLP_new.json', 'r', encoding='utf-8-sig'))\n",
    "\n",
    "word_list = []\n",
    "foslist=[]\n",
    "tags=[]\n",
    "j=0\n",
    "for i in range(len(df['id'])):\n",
    "    paper_id=int(df['id'][i])\n",
    "    # print('-----------')\n",
    "    if i==0:\n",
    "        foslist = df['fos'].loc[i]\n",
    "        for t in foslist:\n",
    "            tagname=t['name']\n",
    "            word_list.append({'tag': tagname, 'id': j})\n",
    "            length = len(foslist)\n",
    "            weight = 1 / length\n",
    "            weight = round(weight, 3)\n",
    "            dictionary = {\n",
    "                \"paperid\": paper_id,\n",
    "                \"tagid\": j,\n",
    "                \"tag\": tagname\n",
    "            }\n",
    "            with open(\"D:/Short Datasets/DBLP_V12_Relations/IR/papers_tags.txt\", \"a+\") as text_file:\n",
    "                text_file.write(\"%s %s %s\" % (df['id'][i], j, weight))\n",
    "                tags.append(tagname)\n",
    "                text_file.write(\"\\n\")\n",
    "            with open('D:/Short Datasets/DBLP_V12_Relations/IR/tags_IR.json', 'a+', encoding='utf-8') as outfile:\n",
    "                json.dump(dictionary, outfile)\n",
    "                outfile.write(\"\\n\")\n",
    "                outfile.write(\",\")\n",
    "            j=j+1\n",
    "    else:\n",
    "        foslist = df['fos'].loc[i]\n",
    "\n",
    "        if str(foslist)!='nan':\n",
    "            for k in foslist:\n",
    "                length = len(foslist)\n",
    "                weight = 1 / length\n",
    "                weight = round(weight, 3)\n",
    "                if k['name'] not in tags:\n",
    "                    word_list.append({'tag': k['name'], 'id': j})\n",
    "                    with open(\"D:/Short Datasets/DBLP_V12_Relations/IR/papers_tags.txt\", \"a+\") as text_file:\n",
    "                        text_file.write(\"%s %s %s\" % (df['id'][i], j, weight))\n",
    "                        tags.append(k['name'])\n",
    "                        text_file.write(\"\\n\")\n",
    "                    dictionary = {\n",
    "                        \"paperid\": paper_id,\n",
    "                        \"tagid\": j,\n",
    "                        \"tag\": k['name']\n",
    "                    }\n",
    "                    with open('D:/Short Datasets/DBLP_V12_Relations/IR/tags_IR.json', 'a+', encoding='utf-8') as outfile:\n",
    "                        json.dump(dictionary, outfile)\n",
    "                        outfile.write(\"\\n\")\n",
    "                        outfile.write(\",\")\n",
    "                    j=j+1\n",
    "                else:\n",
    "                    for g in word_list:\n",
    "                        if k['name'] == g['tag'] and g['tag'] in tags:\n",
    "                            with open(\"D:/Short Datasets/DBLP_V12_Relations/IR/papers_tags.txt\", \"a+\") as text_file:\n",
    "                                text_file.write(\"%s %s %s\" % (df['id'][i], g['id'], weight))\n",
    "                                text_file.write(\"\\n\")\n",
    "                            dictionary = {\n",
    "                                \"paperid\": paper_id,\n",
    "                                \"tagid\": g['id'],\n",
    "                                \"tag\": k['name']\n",
    "                            }\n",
    "                            with open('D:/Short Datasets/DBLP_V12_Relations/IR/tags_IR.json', 'a+', encoding='utf-8') as outfile:\n",
    "                                json.dump(dictionary, outfile)\n",
    "                                outfile.write(\"\\n\")\n",
    "                                outfile.write(\",\")\n",
    "                    j=j+1\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350364"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
